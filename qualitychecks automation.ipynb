{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40589f81-c0cb-4945-be6b-093ee125b95c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzipfile\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import pysurveycto\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "import re\n",
    "import pywhatkit as kit\n",
    "import time\n",
    "import warnings as wn\n",
    "wn.filterwarnings(\"ignore\")\n",
    "import streamlit as st "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5a649-1953-4ecf-bee2-0915ae790819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey login credentials\n",
    "server_name = \"rtvuganda\"\n",
    "username = \"raphael@raisingthevillage.org\"\n",
    "password = \"Evaluation2022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec95ad-d8e0-415f-bf8c-39294a5da131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the credentials to the server\n",
    "scto = pysurveycto.SurveyCTOObject(server_name, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b38143-8869-46d4-9fc3-b933f99e9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current survey form id\n",
    "form_id = \"bhs_2025_rtv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363307a-f060-4975-bd7c-187b5557eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form_id = \"bhs_pilot_2025_rtv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8cac2-92e8-42f9-a1fb-1fc728961dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the survey data from the survey\n",
    "my_form_data = scto.get_form_data(form_id, format=\"json\", shape=\"long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a1935-1f34-49d0-a8c1-061caf10474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the extracted data to pandas data frame\n",
    "data = pd.DataFrame(my_form_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a60807",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"allbhs2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007df85c-ec0e-46a6-a5b4-d52abe641fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting submissionDate to pandas data time format\n",
    "data['SubmissionDate'] = pd.to_datetime(data['SubmissionDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a61e83e-e3e7-4853-b99c-aa64bb1676a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating the yesterday date for easy tracking samples of yesterday\n",
    "yesterday = (datetime.today() - timedelta(days=1)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dba624-d057-4e20-b930-ecdb5d51a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the data of status and consent_1 form surverycto datatypes to pandas float datatype\n",
    "data[['status', 'consent_1']] = data[['status', 'consent_1']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9138942",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SubmissionDate'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df1f40-bcd8-4640-955e-de6688a0cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the data for the previous day and data for samples fully completed\n",
    "data = data[\n",
    "    (data['SubmissionDate'].dt.date == yesterday) &\n",
    "    ((data['status'] == 1) | (data['status'] == 7)) &\n",
    "    (data['consent_1'] == 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aecc1a1-7b05-4412-b291-22f9f13230d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the starttime to datatime in pandas\n",
    "data['starttime'] = pd.to_datetime(data['starttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf34f9ad-86b3-47f8-8ee4-e1beccbb3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the endtime to datatime in pandas\n",
    "data['endtime']=pd.to_datetime(data['endtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20005c93-e7a4-4974-8095-ae1bdbc8464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting duration to numeric\n",
    "data['duration'] = pd.to_numeric(data['duration'], errors='coerce') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d53e7-de43-4c33-ac2d-dd12151a08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing excel files with columns to drop to enhance styling process of the dataframe\n",
    "# please include all columns to drop in this sheet\n",
    "column_drop_df=pd.read_excel(r\"C:\\\\Users\\\\Edison New\\\\Desktop\\\\edison jupyter\\\\Copy of qualitychecks_columns_drop.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c29344-eb9b-4838-bbfc-2d9ad43bc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to drop to drop columns and  dropping columns from data\n",
    "def columns_drop(data, column_drop_df):\n",
    "    columns_to_drop = column_drop_df['Column Names'].to_list()\n",
    "    data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "    return data\n",
    "# dropping un wanted columns from data\n",
    "data = columns_drop(data, column_drop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dab7b0-efc0-4067-82b0-4cc5238d8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the duration from seconds to minutes under new variable duration2\n",
    "data['duration2']=data['duration']/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f58625-6e95-4e5c-9a4b-70e5bcaa36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the column check for samples started beyond 8PM\n",
    "data['is_start_time_beyond_8pm'] = (pd.to_datetime(data['starttime']).dt.hour >= 20).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e6a6a-4d89-4856-8991-4b3a6db3b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking whether there if date difference between when the sample was started vs endtime of the sample\n",
    "data['starttime'] = pd.to_datetime(data['starttime']).dt.date\n",
    "data['endtime'] = pd.to_datetime(data['endtime']).dt.date\n",
    "data['date_difference'] = (data['endtime'] - data['starttime']).apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947b753-8d73-40d3-9359-140d30b11616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop\n",
    "data['is_duration_invalid']=((data['duration2']<20) | (data['duration2']>60)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3182d1-01c9-4cbe-ae25-c5529b3111c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns for samples collected by enumerator the pervious day\n",
    "data['sample'] = data['enumerator_name'].map(data['enumerator_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa04f99-0a85-4cd9-a523-a5afc374ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = ['beans', 'maize','peas','cassava']  \n",
    "season = [1, 2]\n",
    "state = ['fresh', 'dry']\n",
    "price_1 = []\n",
    "\n",
    "for i in season:\n",
    "    for j in list_:\n",
    "        for k in state:\n",
    "            price1 = f'sn_{i}_{j}_Market_Price_{k}'\n",
    "            if price1 in data.columns:\n",
    "                price_1.append(price1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27619c3-5265-4c1f-9259-258ff05f71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list=['gnuts','yams','sweetpotatoes','irish_potatoes',\n",
    "      'ginger','garlic','rice','sorghum','millet',\n",
    "      'soya_beans']\n",
    "season=[1,2]\n",
    "price_2=[]\n",
    "for i in list:\n",
    "    for j in season:\n",
    "        price1=f'sn_{j}_{i}_Market_Price'\n",
    "        if price1 in data.columns:\n",
    "            price_2.append(price1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15e717-6678-4639-af90-27485353504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging prices of seasonal crops into one list for ease accessibility\n",
    "season_crop_prices=price_1+price_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfeafa-ad2f-4f29-b0ef-e4f086929f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all season crop prices to numeric from json data structures\n",
    "for column in season_crop_prices:\n",
    "    data[column] = pd.to_numeric(data[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64da2a-64aa-4e7c-bc54-f3a8ef1ef221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the excel sheet with min,max of major seasonal crops,vegetables, perennial crops\n",
    "price_df=pd.read_excel(\"crop_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207de4cd-5b90-4e9d-8822-2f743e59d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting vegetables prices from the data to lists for easy accessibility\n",
    "veg = [\n",
    "    \"Pumpkins\",\n",
    "    \"Carrots\",\n",
    "    \"onions\",\n",
    "    \"green_pepper\",\n",
    "    \"hot_pepper\",\n",
    "    \"cabbage\",\n",
    "    \"tomato\",\n",
    "    \"watermelon\",\n",
    "    \"spinach\",\n",
    "    \"cauliflower\",\n",
    "    \"sukuma_wiki\",\n",
    "    \"beetroot\",\n",
    "    \"blacknightshade\",\n",
    "    \"white_eggplant\",\n",
    "    \"green_eggplant\",\n",
    "    \"purple_eggplant\",\n",
    "    \"dodo\"\n",
    "]\n",
    "season=[1,2]\n",
    "veg_list=[]\n",
    "for k in veg:\n",
    "    for j in season:\n",
    "        vegk=f'sn_{j}_{k}_Market_Price'\n",
    "        if vegk in data.columns:\n",
    "            veg_list.append(vegk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b310d658-25c5-48ba-83a4-0e3958d44960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all seasonal crops ans seasons\n",
    "crops=['gnuts','beans','irish_potatoes','maize','peas',\n",
    "      'ginger','garlic','rice','barley','sorghum','millet',\n",
    "      'soya_beans']\n",
    "seasons=[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d8925-7ce0-42e6-a9dc-1dd0169a4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all seasonal crop total_yield and total quantity planted to numeric\n",
    "for crop in crops:\n",
    "    for season in seasons:\n",
    "        total_yield = f'sn_{season}_{crop}_Total_Yield'\n",
    "        planted = f'sn_{season}_{crop}_planted'\n",
    "        \n",
    "        if total_yield not in data.columns:\n",
    "            data[total_yield] = np.nan\n",
    "        if planted not in data.columns:\n",
    "            data[planted] = np.nan\n",
    "        data[total_yield] = pd.to_numeric(data[total_yield], errors='coerce')\n",
    "        data[planted] = pd.to_numeric(data[planted], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726daecb-f6eb-47d3-a786-99ad882eb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to compute yield per  unit\n",
    "def calculate_yield_per_plant(data, crops, seasons):\n",
    "    result = data.copy()\n",
    "    \n",
    "    for crop in crops:\n",
    "        for season in seasons:\n",
    "            total_yield = f'sn_{season}_{crop}_Total_Yield'\n",
    "            planted = f'sn_{season}_{crop}_planted'\n",
    "            yield_per_plant = f'sn_{season}_{crop}_yp'\n",
    "            \n",
    "            # Ensure the yield_per_plant column exists\n",
    "            if yield_per_plant not in result.columns:\n",
    "                result[yield_per_plant] = np.nan\n",
    "\n",
    "            if total_yield in result.columns and planted in result.columns:\n",
    "                # Identify rows where both total_yield and planted are missing\n",
    "                null_mask = result[total_yield].isna() & result[planted].isna()\n",
    "                result.loc[null_mask, yield_per_plant] = np.nan  # Explicitly set to NaN\n",
    "                \n",
    "                # Compute yield per plant where valid values exist\n",
    "                mask = (\n",
    "                    pd.notna(result[total_yield]) & \n",
    "                    pd.notna(result[planted]) & \n",
    "                    (result[planted] != 0)\n",
    "                )\n",
    "                \n",
    "                if mask.any():\n",
    "                    result.loc[mask, yield_per_plant] = (\n",
    "                        result.loc[mask, total_yield] / result.loc[mask, planted]\n",
    "                    )\n",
    "                    \n",
    "                    # Replace infinite values with NaN\n",
    "                    result[yield_per_plant].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    return result\n",
    "data = calculate_yield_per_plant(data, crops, seasons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293d1a6-d28c-4ccf-a65f-49a0fd1dced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all these columns below to numeric \n",
    "required_columns = [\n",
    "    'Distance_travelled_one_way_OPD_treatment', 'Time_travel_one_way_trip_OPD_treatment_minutes',\n",
    "    'water_distance_collect_water_round_trip', 'hh_water_collection_Minutes', 'distance_primary_market',\n",
    "    'time_primary_market', 'Size_land_owned', 'Value_land_owned', \"govt_assistance_value\", \n",
    "    \"remittance_gifts_children\", \"remittance_gifts_relative\", \"remittance_gifts_friends\",\n",
    "    \"casual_work_wage_member1\", \"casual_work_inkind_member1\", \"casual_work_wage_member2\", \n",
    "    \"casual_work_inkind_member2\", \"casual_work_wage_member3\", \"casual_work_inkind_member3\", \n",
    "    \"casual_work_wage_member4\", \"casual_work_inkind_member4\", \"casual_work_wage_member5\", \n",
    "    \"casual_work_inkind_member5\", \"casual_work_wage_member6\", \"casual_work_inkind_member6\"\n",
    "]\n",
    "\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        data[col] = np.nan\n",
    "\n",
    "\n",
    "data[required_columns] = data[required_columns].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838d524-e317-4960-884f-9c37588fabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the other columns to numeric\n",
    "col_price = [i for i in data.columns if \"price\" in i or \"payment_fees_labour\" in i or \"remittance\" in i or \"market_ppu\" in i or \"Price\" in i]\n",
    "data[col_price] = data[col_price].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655727fa-eed2-4d26-bf01-b8fb367e529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function computing total number of errors\n",
    "price_df = price_df.set_index('Crop')\n",
    "def check_price_violations(row):\n",
    "    errors = 0  \n",
    "    for crop in price_df.index:\n",
    "        if crop in row:  \n",
    "            if row[crop] < price_df.loc[crop, 'Min'] or row[crop] > price_df.loc[crop, 'Max']:\n",
    "                errors += 1  \n",
    "    return errors\n",
    "data['error'] = data.apply(check_price_violations, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b58bd-26ea-47d2-a458-2d3f319c2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df=price_df.reset_index('Crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f5273-f836-4289-b0c0-13d977685623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_out_of_range(cell_value, min_value, max_value):\n",
    "    if pd.notna(cell_value) and isinstance(cell_value, (int, float)):  # Ensure it's numeric\n",
    "        if cell_value < min_value or cell_value > max_value:\n",
    "            return \"background-color: red\"\n",
    "    return \"\"\n",
    "\n",
    "def apply_highlighting(data, price_df):\n",
    "    # Convert price_df to a dictionary for fast lookup (case insensitive)\n",
    "    crop_prices = {row[\"Crop\"].strip(): (row[\"Min\"], row[\"Max\"]) for _, row in price_df.iterrows()}\n",
    "\n",
    "    # Apply the highlighting function column-wise\n",
    "    def highlight_column(column):\n",
    "        crop_name = column.name.strip()  # Normalize column name\n",
    "        price_range = crop_prices.get(crop_name)  # Safe dictionary lookup\n",
    "        if price_range:\n",
    "            min_price, max_price = price_range\n",
    "            return column.apply(lambda x: highlight_out_of_range(x, min_price, max_price))\n",
    "        return [\"\"] * len(column)  # No styling if no matching crop\n",
    "\n",
    "    return data.style.apply(highlight_column, subset=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a8641-a814-4298-b4c2-5f35e7be785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [i for i in data.columns if \"Value_remittance_gift\" in i or \"Value_payment_fees_labour\" in i or 'remittance' in i]\n",
    "\n",
    "def extract_crop(col_name):\n",
    "    match = re.search(r'sn_\\d+_([a-zA-Z_]+)_Yield|sn_\\d+_([a-zA-Z_]+)_Value|([a-zA-Z_]+)_Yield|([a-zA-Z_]+)_Value|([a-zA-Z_]+)_remittance|([a-zA-Z_]+)_payment_fees', col_name)\n",
    "    if match:\n",
    "        return match.group(1) or match.group(2) or match.group(3) or match.group(4) or match.group(5) or match.group(6)\n",
    "    return \"Unknown\"\n",
    "df = pd.DataFrame({'Column Name': col, 'Crop Name': [extract_crop(coll) for coll in col]})\n",
    "data[col] = data[col].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a5750-5d88-4f1e-b62b-8b5d6fbd2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_number = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,97] \n",
    "for bus in business_number:\n",
    "    bus_sa = f'business{bus}_sales'\n",
    "    bus_po = f'business{bus}_profit'\n",
    "    if bus_sa not in data.columns and bus_po not in data.columns:\n",
    "        data[bus_sa]=np.nan\n",
    "        data[bus_po]=np.nan\n",
    "    \n",
    "    if bus_sa in data.columns and bus_po in data.columns:\n",
    "        data[[bus_sa,bus_po]]=data[[bus_sa,bus_po]].astype(float)\n",
    "    else:\n",
    "        print(f\"Columns {bus_sa} or {bus_po} do not exist in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06338dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def business_error(row):\n",
    "    error = 0\n",
    "    for i in business_number:\n",
    "        bus_sa = f'business{i}_sales'\n",
    "        bus_po = f'business{i}_profit'\n",
    "        if pd.notna(row[bus_po]) and pd.notna(row[bus_sa]):\n",
    "            if row[bus_po] > row[bus_sa]:\n",
    "                error += 1\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b274323-005b-4c28-baee-d286600f6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def business_error(row):\n",
    "#     error_bus = 0  \n",
    "\n",
    "#     for bus in range(1, 29):  # Loop through business numbers from 1 to 28\n",
    "#         bus_sa = f'business{bus}_sales'\n",
    "#         bus_po = f'business{bus}_profit'\n",
    "\n",
    "#         # Use .get() to avoid KeyErrors\n",
    "#         sales = row.get(bus_sa, None)\n",
    "#         profit = row.get(bus_po, None)\n",
    "\n",
    "#         # Ensure both values exist and are numeric before comparison\n",
    "#         if sales is not None and profit is not None:\n",
    "#             try:\n",
    "#                 if float(profit) > float(sales):  \n",
    "#                     error_bus += 1  \n",
    "#             except ValueError:\n",
    "#                 pass  # Ignore non-numeric values\n",
    "\n",
    "#     return error_bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff190dd-f597-4ab7-b60a-fae9d467f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['error_bus']=data.apply(business_error,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de84f0d3-5c7f-4c28-a196-f4eed8707a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['error_bus'].min(),data['error_bus'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c036fd64-bba8-4114-8fe7-88fc2986a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_remittance_highlights(row):\n",
    "    highlight_count = 0  \n",
    "\n",
    "    # Identify relevant columns\n",
    "    cols = [col for col in row.index if any(x in str(col) for x in \n",
    "                [\"Value_remittance_gift\", \"Value_payment_fees_labour\", \"remittance_gifts_friends\"])]\n",
    "\n",
    "    # Iterate through selected columns\n",
    "    for col_name in cols:\n",
    "        if pd.notna(row[col_name]):  \n",
    "            if row[col_name] < 100 or row[col_name] % 100 != 0:\n",
    "                highlight_count += 1  \n",
    "\n",
    "    return highlight_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329d186-e88c-4a31-9514-b281bba19d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['remittance_highlight_count'] = data.apply(count_remittance_highlights, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f2c44-09b8-4f69-9b2f-18fb89feb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['remittance_highlight_count'].min(),data['remittance_highlight_count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c5ed2-da65-4e8b-bc68-272e0ca53750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_travel_errors(row):\n",
    "    error_count = 0  # Initialize error counter\n",
    "\n",
    "    # Define limits for distance and time\n",
    "    travel_checks = {\n",
    "        'Distance_travelled_one_way_OPD_treatment': (0, 28),\n",
    "        'Time_travel_one_way_trip_OPD_treatment_minutes': (0, 420),\n",
    "        'water_distance_collect_water_round_trip': (0, 8),\n",
    "        'hh_water_collection_Minutes': (0, 420),\n",
    "        'distance_primary_market': (0, 10),\n",
    "        'time_primary_market': (0, 420)\n",
    "    }\n",
    "\n",
    "    # Count errors for extreme values (0 or exceeding max limit)\n",
    "    for col, (min_val, max_val) in travel_checks.items():\n",
    "        if col in row:\n",
    "            if row[col] == min_val or row[col] >= max_val:\n",
    "                error_count += 1  # Increment error count\n",
    "\n",
    "    # Walking speed rule: Expected travel time based on distance\n",
    "    if 'Distance_travelled_one_way_OPD_treatment' in row and 'Time_travel_one_way_trip_OPD_treatment_minutes' in row:\n",
    "        expected_time_opd = row['Distance_travelled_one_way_OPD_treatment'] * 40\n",
    "        if row['Time_travel_one_way_trip_OPD_treatment_minutes'] > 1.2 * expected_time_opd:\n",
    "            error_count += 1\n",
    "\n",
    "    if 'water_distance_collect_water_round_trip' in row and 'hh_water_collection_Minutes' in row:\n",
    "        expected_time_water = row['water_distance_collect_water_round_trip'] * 60\n",
    "        if row['hh_water_collection_Minutes'] > 1.2 * expected_time_water:\n",
    "            error_count += 1\n",
    "\n",
    "    if 'distance_primary_market' in row and 'time_primary_market' in row:\n",
    "        expected_time_market = row['distance_primary_market'] * 40\n",
    "        if row['time_primary_market'] > 1.2 * expected_time_market:\n",
    "            error_count += 1\n",
    "\n",
    "    return error_count  # Return total errors for the row\n",
    "\n",
    "# Apply function to compute errors\n",
    "data['travel_errors'] = data.apply(compute_travel_errors, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ba74b-76d1-4b12-a872-aec6113af2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['travel_errors'].min(),data['travel_errors'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4035f7-5829-48d1-89f4-7b548142283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_crop_yield_errors(row):\n",
    "    error_count = 0  # Initialize error counter\n",
    "\n",
    "    # Define crop yield thresholds\n",
    "    crop_yield_thresholds = {\n",
    "        'sn_1_beans_yp': 100, 'sn_2_beans_yp': 100,\n",
    "        'sn_1_maize_yp': 250, 'sn_2_maize_yp': 250,\n",
    "        'sn_1_peas_yp': 150, 'sn_2_peas_yp': 150,\n",
    "        'sn_1_gnuts_yp': 150, 'sn_2_gnuts_yp': 150,\n",
    "        'sn_1_irish_potatoes_yp': 10, 'sn_2_irish_potatoes_yp': 10,\n",
    "        'sn_1_ginger_yp': 100, 'sn_2_ginger_yp': 100,\n",
    "        'sn_1_rice_yp': 150, 'sn_2_rice_yp': 150,\n",
    "        'sn_1_barley_yp': 100, 'sn_2_barley_yp': 100,\n",
    "        'sn_1_sorghum_yp': 100, 'sn_2_sorghum_yp': 100,\n",
    "        'sn_1_millet_yp': 200, 'sn_2_millet_yp': 200,\n",
    "        'sn_1_soya_beans_yp': 100, 'sn_2_soya_beans_yp': 100,\n",
    "        'sn_1_garlic_yp': 100, 'sn_2_garlic_yp': 100\n",
    "    }\n",
    "\n",
    "    # Check for crop yield exceeding thresholds\n",
    "    for crop, threshold in crop_yield_thresholds.items():\n",
    "        if crop in row and row[crop] > threshold:\n",
    "            error_count += 1  # Increment error count\n",
    "\n",
    "    return error_count  # Return total errors for the row\n",
    "\n",
    "# Apply function to compute crop yield errors\n",
    "data['crop_yield_errors'] = data.apply(compute_crop_yield_errors, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1fe32-41bb-411b-9cb9-39ea180b8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['crop_yield_errors'].min(),data['crop_yield_errors'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe1478-5486-42b0-9a41-752f89a2c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_land_value_errors(row):\n",
    "    error_count = 0  # Initialize error counter\n",
    "\n",
    "    # Land Value Check\n",
    "    if 'Size_land_owned' in row and 'Value_land_owned' in row:\n",
    "        expected_land_value = row['Size_land_owned'] * 15_000_000  # Expected value per unit size\n",
    "        if row['Value_land_owned'] > expected_land_value:\n",
    "            error_count += 1  # Increment error count\n",
    "\n",
    "    return error_count  # Return total errors for the row\n",
    "\n",
    "# Apply function to compute land value errors\n",
    "data['land_value_errors'] = data.apply(compute_land_value_errors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc6c34-aec1-46c4-996c-c6cf62e3613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['land_value_errors'].min(),data['land_value_errors'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a870d945-fe0d-48f1-8b66-93f4e876389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_time(row):\n",
    "    colors = [''] * len(row)\n",
    "\n",
    "    # Highlight remittance and payment fee values\n",
    "    col = [i for i in data.columns if \"Value_remittance_gift\" in i or \"Value_payment_fees_labour\" in i or 'remittance_gifts_friends' in i]\n",
    "    for col_name in col:\n",
    "        if col_name in row.index and not pd.isna(row[col_name]):\n",
    "            if row[col_name] < 100 or row[col_name] % 100 != 0:\n",
    "                colors[row.index.get_loc(col_name)] = 'background-color:red'\n",
    "\n",
    "    # Sample Check\n",
    "    if row['sample'] < 6:\n",
    "        colors[row.index.get_loc('sample')] = 'background-color:red'\n",
    "\n",
    "    # OPD Travel Checks\n",
    "    if row['Distance_travelled_one_way_OPD_treatment'] == 0 or row['Distance_travelled_one_way_OPD_treatment'] >= 28:\n",
    "        colors[row.index.get_loc('Distance_travelled_one_way_OPD_treatment')] = 'background-color:red'\n",
    "\n",
    "    if row['Time_travel_one_way_trip_OPD_treatment_minutes'] == 0 or row['Time_travel_one_way_trip_OPD_treatment_minutes'] >= 420:\n",
    "        colors[row.index.get_loc('Time_travel_one_way_trip_OPD_treatment_minutes')] = 'background-color:red'\n",
    "\n",
    "    # Water Collection Checks\n",
    "    if row['water_distance_collect_water_round_trip'] == 0 or row['water_distance_collect_water_round_trip'] > 8:\n",
    "        colors[row.index.get_loc('water_distance_collect_water_round_trip')] = 'background-color:red'\n",
    "\n",
    "    if row['hh_water_collection_Minutes'] == 0 or row['hh_water_collection_Minutes'] >= 420:\n",
    "        colors[row.index.get_loc('hh_water_collection_Minutes')] = 'background-color:red'\n",
    "\n",
    "    # Market Travel Checks\n",
    "    if row['distance_primary_market'] == 0 or row['distance_primary_market'] > 10:\n",
    "        colors[row.index.get_loc('distance_primary_market')] = 'background-color:red'\n",
    "\n",
    "    if row['time_primary_market'] == 0 or row['time_primary_market'] >= 420:\n",
    "        colors[row.index.get_loc('time_primary_market')] = 'background-color:red'\n",
    "\n",
    "    # 🚨 Walking Speed Rule Check (Only for high travel time)\n",
    "    expected_time_opd = row['Distance_travelled_one_way_OPD_treatment'] * 40\n",
    "    if row['Time_travel_one_way_trip_OPD_treatment_minutes'] > 1.2 * expected_time_opd:\n",
    "        colors[row.index.get_loc('Distance_travelled_one_way_OPD_treatment')] = 'background-color:red'\n",
    "        colors[row.index.get_loc('Time_travel_one_way_trip_OPD_treatment_minutes')] = 'background-color:red'\n",
    "\n",
    "    expected_time_water = row['water_distance_collect_water_round_trip'] * 60\n",
    "    if row['hh_water_collection_Minutes'] > 1.2 * expected_time_water:\n",
    "        colors[row.index.get_loc('water_distance_collect_water_round_trip')] = 'background-color:red'\n",
    "        colors[row.index.get_loc('hh_water_collection_Minutes')] = 'background-color:red'\n",
    "\n",
    "    expected_time_market = row['distance_primary_market'] * 40\n",
    "    if row['time_primary_market'] > 1.2 * expected_time_market:\n",
    "        colors[row.index.get_loc('distance_primary_market')] = 'background-color:red'\n",
    "        colors[row.index.get_loc('time_primary_market')] = 'background-color:red'\n",
    "\n",
    "    # Business Check\n",
    "    business_number = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,97]\n",
    "    for bus in business_number:\n",
    "        bus_sa = f'business{bus}_sales'\n",
    "        bus_po = f'business{bus}_profit'\n",
    "        if bus_sa in row.index and bus_po in row.index:\n",
    "            if row[bus_po] > row[bus_sa]:\n",
    "                colors[row.index.get_loc(bus_po)] = 'background-color:red'\n",
    "                colors[row.index.get_loc(bus_sa)] = 'background-color:red'\n",
    "\n",
    "    # Crop Yield Checks\n",
    "    crop_yield_thresholds = {\n",
    "        'sn_1_beans_yp': 100, 'sn_2_beans_yp': 100,\n",
    "        'sn_1_maize_yp': 250, 'sn_2_maize_yp': 250,\n",
    "        'sn_1_peas_yp': 150, 'sn_2_peas_yp': 150,\n",
    "        'sn_1_gnuts_yp': 150, 'sn_2_gnuts_yp': 150,\n",
    "        'sn_1_irish_potatoes_yp': 10, 'sn_2_irish_potatoes_yp': 10,\n",
    "        'sn_1_ginger_yp': 100, 'sn_2_ginger_yp': 100,\n",
    "        'sn_1_rice_yp': 150, 'sn_2_rice_yp': 150,\n",
    "        'sn_1_barley_yp': 100, 'sn_2_barley_yp': 100,\n",
    "        'sn_1_sorghum_yp': 100, 'sn_2_sorghum_yp': 100,\n",
    "        'sn_1_millet_yp': 200, 'sn_2_millet_yp': 200,\n",
    "        'sn_1_soya_beans_yp': 100, 'sn_2_soya_beans_yp': 100,\n",
    "        'sn_1_garlic_yp': 100, 'sn_2_garlic_yp': 100\n",
    "    }\n",
    "\n",
    "    for crop, threshold in crop_yield_thresholds.items():\n",
    "        if crop in row.index and row[crop] > threshold:\n",
    "            colors[row.index.get_loc(crop.replace(\"_yp\", \"_planted\"))] = 'background-color:red'\n",
    "            colors[row.index.get_loc(crop.replace(\"_yp\", \"_Total_Yield\"))] = 'background-color:red'\n",
    "            colors[row.index.get_loc(crop)] = 'background-color:red'\n",
    "\n",
    "    # Land Value Check\n",
    "    if 'Size_land_owned' in row.index and 'Value_land_owned' in row.index:\n",
    "        expected_land_value = row['Size_land_owned'] * 15000000\n",
    "        if row['Value_land_owned'] > expected_land_value:\n",
    "            colors[row.index.get_loc('Size_land_owned')] = 'background-color:red'\n",
    "            colors[row.index.get_loc('Value_land_owned')] = 'background-color:red'\n",
    "\n",
    "    # Time Checks\n",
    "    if 'is_start_time_beyond_8pm' in row.index and row['is_start_time_beyond_8pm'] == 1:\n",
    "        colors[row.index.get_loc('starttime')] = 'background-color:red'\n",
    "\n",
    "    if 'is_duration_invalid' in row.index and row['is_duration_invalid'] == 1:\n",
    "        colors[row.index.get_loc('duration2')] = 'background-color:red'\n",
    "\n",
    "    # Date Difference Check\n",
    "    if 'date_difference' in row.index and row['date_difference'] > 0:\n",
    "        colors[row.index.get_loc('starttime')] = 'background-color:red'\n",
    "        colors[row.index.get_loc('endtime')] = 'background-color:red'\n",
    "\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be1446-db50-4b09-8fee-8b83e0360b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "styled=styled_df = apply_highlighting(data, price_df).apply(highlight_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332ff21-5180-4329-81b4-d5b181187568",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_output=\"styled_output2.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264252d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"styler.render.max_elements\", 2660658)\n",
    "# st.dataframe(styled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94bab1-e2a7-43a1-8809-182b83bc2404",
   "metadata": {},
   "outputs": [],
   "source": [
    "styled.to_excel(excel_output, engine=\"openpyxl\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe4cce-76b0-47d7-beec-12e2c729f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f891e30-d5a5-4457-ad12-bb0923999582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipient_number = \"+256752537353\"\n",
    "# kit.sendwhats_image(recipient_number, excel_output, \"Here is the analysis result.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac16425e-b6b9-4580-8749-5aa65762ff2e",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
